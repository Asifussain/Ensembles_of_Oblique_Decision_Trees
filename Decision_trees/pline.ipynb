{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\vs code\\DecisionTrees\\Ensembles_of_Oblique_Decision_Trees\\Decision_trees\\DNDT.py:13: The name tf.disable_eager_execution is deprecated. Please use tf.compat.v1.disable_eager_execution instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from WODT import *\n",
    "from HouseHolder_CART import *\n",
    "from RandCART import *\n",
    "from CO2 import *\n",
    "from NDT import *\n",
    "from Oblique_Classifier_1 import *\n",
    "from DNDT import *\n",
    "from segmentor import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: d:\\vs code\\DecisionTrees\\Ensembles_of_Oblique_Decision_Trees\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "os.chdir('d:/vs code/DecisionTrees/Ensembles_of_Oblique_Decision_Trees')\n",
    "print(\"Current working directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(dataset):\n",
    "    X, y = None, None\n",
    "\n",
    "    if dataset == 'abalone':\n",
    "        X_data = pd.read_csv('dataset/abalone/abalone_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/abalone/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'acute-inflammation':\n",
    "        X_data = pd.read_csv('dataset/acute-inflammation/acute-inflammation_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/acute-inflammation/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'acute-nephritis':\n",
    "        X_data = pd.read_csv('dataset/acute-nephritis/acute-nephritis_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/acute-nephritis/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'adult':\n",
    "        X_data = pd.read_csv('dataset/adult/adult_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/adult/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'annealing':\n",
    "        X_data = pd.read_csv('dataset/annealing/annealing_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/annealing/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'arrhythmia':\n",
    "        X_data = pd.read_csv('dataset/arrhythmia/arrhythmia_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/arrhythmia/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'audiology-std':\n",
    "        X_data = pd.read_csv('dataset/audiology-std/audiology-std_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/audiology-std/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'balance-scale':\n",
    "        X_data = pd.read_csv('dataset/balance-scale/balance-scale_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/balance-scale/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'balloons':\n",
    "        X_data = pd.read_csv('dataset/balloons/balloons_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/balloons/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'bank':\n",
    "        X_data = pd.read_csv('dataset/bank/bank_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/bank/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'blood':\n",
    "        X_data = pd.read_csv('dataset/blood/blood_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/blood/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'breast-cancer':\n",
    "        X_data = pd.read_csv('dataset/breast-cancer/breast-cancer_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/breast-cancer/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "        \n",
    "    elif dataset == 'breast-cancer-wisc':\n",
    "        X_data = pd.read_csv('dataset/breast-cancer-wisc/breast-cancer-wisc_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/breast-cancer-wisc/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'breast-cancer-wisc-diag':\n",
    "        X_data = pd.read_csv('dataset/breast-cancer-wisc-diag/breast-cancer-wisc-diag_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/breast-cancer-wisc-diag/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'breast-cancer-wisc-prog':\n",
    "        X_data = pd.read_csv('dataset/breast-cancer-wisc-prog/breast-cancer-wisc-prog_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/breast-cancer-wisc-prog/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'breast-tissue':\n",
    "        X_data = pd.read_csv('dataset/breast-tissue/breast-tissue_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/breast-tissue/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'car':\n",
    "        X_data = pd.read_csv('dataset/car/car_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/car/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'cardiotocography-3clases':\n",
    "        X_data = pd.read_csv('dataset/cardiotocography-3clases/cardiotocography-3clases_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/cardiotocography-3clases/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'cardiotocography-10clases':\n",
    "        X_data = pd.read_csv('dataset/cardiotocography-10clases/cardiotocography-10clases_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/cardiotocography-10clases/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'chess-krvk':\n",
    "        X_data = pd.read_csv('dataset/chess-krvk/chess-krvk_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/chess-krvk/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'chess-krvkp':\n",
    "        X_data = pd.read_csv('dataset/chess-krvkp/chess-krvkp_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/chess-krvkp/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'congressional-voting':\n",
    "        X_data = pd.read_csv('dataset/congressional-voting/congressional-voting_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/congressional-voting/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'conn-bench-sonar-mines-rocks':\n",
    "        X_data = pd.read_csv('dataset/conn-bench-sonar-mines-rocks/conn-bench-sonar-mines-rocks_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/conn-bench-sonar-mines-rocks/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'conn-bench-vowel-deterding':\n",
    "        X_data = pd.read_csv('dataset/conn-bench-vowel-deterding/conn-bench-vowel-deterding_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/conn-bench-vowel-deterding/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'connect-4':\n",
    "        X_data = pd.read_csv('dataset/connect-4/connect-4_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/connect-4/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'contrac':\n",
    "        X_data = pd.read_csv('dataset/contrac/contrac_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/contrac/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'credit-approval':\n",
    "        X_data = pd.read_csv('dataset/credit-approval/credit-approval_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/credit-approval/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'cylinder-bands':\n",
    "        X_data = pd.read_csv('dataset/cylinder-bands/cylinder-bands_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/cylinder-bands/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'dermatology':\n",
    "        X_data = pd.read_csv('dataset/dermatology/dermatology_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/dermatology/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'echocardiogram':\n",
    "        X_data = pd.read_csv('dataset/echocardiogram/echocardiogram_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/echocardiogram/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'ecoli':\n",
    "        X_data = pd.read_csv('dataset/ecoli/ecoli_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/ecoli/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'energy-y1':\n",
    "        X_data = pd.read_csv('dataset/energy-y1/energy-y1_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/energy-y1/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'energy-y2':\n",
    "        X_data = pd.read_csv('dataset/energy-y2/energy-y2_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/energy-y2/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'fertility':\n",
    "        X_data = pd.read_csv('dataset/fertility/fertility_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/fertility/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'flags':\n",
    "        X_data = pd.read_csv('dataset/flags/flags_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/flags/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'glass':\n",
    "        X_data = pd.read_csv('dataset/glass/glass_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/glass/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'haberman-survival':\n",
    "        X_data = pd.read_csv('dataset/haberman-survival/haberman-survival_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/haberman-survival/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'hayes-roth':\n",
    "        X_data = pd.read_csv('dataset/hayes-roth/hayes-roth_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/hayes-roth/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'heart-cleveland':\n",
    "        X_data = pd.read_csv('dataset/heart-cleveland/heart-cleveland_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/heart-cleveland/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'heart-hungarian':\n",
    "        X_data = pd.read_csv('dataset/heart-hungarian/heart-hungarian_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/heart-hungarian/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'heart-switzerland':\n",
    "        X_data = pd.read_csv('dataset/heart-switzerland/heart-switzerland_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/heart-switzerland/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'heart-va':\n",
    "        X_data = pd.read_csv('dataset/heart-va/heart-va_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/heart-va/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'hepatitis':\n",
    "        X_data = pd.read_csv('dataset/hepatitis/hepatitis_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/hepatitis/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'hill-valley':\n",
    "        X_data = pd.read_csv('dataset/hill-valley/hill-valley_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/hill-valley/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'horse-colic':\n",
    "        X_data = pd.read_csv('dataset/horse-colic/horse-colic_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/horse-colic/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'ilpd-indian-liver':\n",
    "        X_data = pd.read_csv('dataset/ilpd-indian-liver/ilpd-indian-liver_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/ilpd-indian-liver/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'image-segmentation':\n",
    "        X_data = pd.read_csv('dataset/image-segmentation/image-segmentation_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/image-segmentation/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'ionosphere':\n",
    "        X_data = pd.read_csv('dataset/ionosphere/ionosphere_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/ionosphere/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'iris':\n",
    "        X_data = pd.read_csv('dataset/iris/iris_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/iris/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'led-display':\n",
    "        X_data = pd.read_csv('dataset/led-display/led-display_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/led-display/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'lenses':\n",
    "        X_data = pd.read_csv('dataset/lenses/lenses_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/lenses/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'letter':\n",
    "        X_data = pd.read_csv('dataset/letter/letter_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/letter/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'libras':\n",
    "        X_data = pd.read_csv('dataset/libras/libras_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/libras/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'low-res-spect':\n",
    "        X_data = pd.read_csv('dataset/low-res-spect/low-res-spect_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/low-res-spect/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'lung-cancer':\n",
    "        X_data = pd.read_csv('dataset/lung-cancer/lung-cancer_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/lung-cancer/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'lymphography':\n",
    "        X_data = pd.read_csv('dataset/lymphography/lymphography_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/lymphography/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'magic':\n",
    "        X_data = pd.read_csv('dataset/magic/magic_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/magic/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'mammographic':\n",
    "        X_data = pd.read_csv('dataset/mammographic/mammographic_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/mammographic/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'miniboone':\n",
    "        X_data = pd.read_csv('dataset/miniboone/miniboone_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/miniboone/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'molec-biol-promoter':\n",
    "        X_data = pd.read_csv('dataset/molec-biol-promoter/molec-biol-promoter_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/molec-biol-promoter/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'molec-biol-splice':\n",
    "        X_data = pd.read_csv('dataset/molec-biol-splice/molec-biol-splice_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/molec-biol-splice/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'monks-1':\n",
    "        X_data = pd.read_csv('dataset/monks-1/monks-1_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/monks-1/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'monks-2':\n",
    "        X_data = pd.read_csv('dataset/monks-2/monks-2_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/monks-2/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'monks-3':\n",
    "        X_data = pd.read_csv('dataset/monks-3/monks-3_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/monks-3/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'mushroom':\n",
    "        X_data = pd.read_csv('dataset/mushroom/mushroom_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/mushroom/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'musk-1':\n",
    "        X_data = pd.read_csv('dataset/musk-1/musk-1_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/musk-1/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'musk-2':\n",
    "        X_data = pd.read_csv('dataset/musk-2/musk-2_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/musk-2/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'nursery':\n",
    "        X_data = pd.read_csv('dataset/nursery/nursery_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/nursery/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'oocytes_merluccius_nucleus_4d':\n",
    "        X_data = pd.read_csv('dataset/oocytes_merluccius_nucleus_4d/oocytes_merluccius_nucleus_4d_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/oocytes_merluccius_nucleus_4d/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'oocytes_merluccius_states_2f':\n",
    "        X_data = pd.read_csv('dataset/oocytes_merluccius_states_2f/oocytes_merluccius_states_2f_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/oocytes_merluccius_states_2f/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'oocytes_trisopterus_nucleus_2f':\n",
    "        X_data = pd.read_csv('dataset/oocytes_trisopterus_nucleus_2f/oocytes_trisopterus_nucleus_2f_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/oocytes_trisopterus_nucleus_2f/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'oocytes_trisopterus_states_5b':\n",
    "        X_data = pd.read_csv('dataset/oocytes_trisopterus_states_5b/oocytes_trisopterus_states_5b_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/oocytes_trisopterus_states_5b/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'optical':\n",
    "        X_data = pd.read_csv('dataset/optical/optical_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/optical/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'ozone':\n",
    "        X_data = pd.read_csv('dataset/ozone/ozone_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/ozone/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'page-blocks':\n",
    "        X_data = pd.read_csv('dataset/page-blocks/page-blocks_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/page-blocks/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'parkinsons':\n",
    "        X_data = pd.read_csv('dataset/parkinsons/parkinsons_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/parkinsons/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'pendigits':\n",
    "        X_data = pd.read_csv('dataset/pendigits/pendigits_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/pendigits/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'pima':\n",
    "        X_data = pd.read_csv('dataset/pima/pima_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/pima/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'pittsburg-bridges-MATERIAL':\n",
    "        X_data = pd.read_csv('dataset/pittsburg-bridges-MATERIAL/pittsburg-bridges-MATERIAL_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/pittsburg-bridges-MATERIAL/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'pittsburg-bridges-REL-L':\n",
    "        X_data = pd.read_csv('dataset/pittsburg-bridges-REL-L/pittsburg-bridges-REL-L_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/pittsburg-bridges-REL-L/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'pittsburg-bridges-SPAN':\n",
    "        X_data = pd.read_csv('dataset/pittsburg-bridges-SPAN/pittsburg-bridges-SPAN_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/pittsburg-bridges-SPAN/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'pittsburg-bridges-T-OR-D':\n",
    "        X_data = pd.read_csv('dataset/pittsburg-bridges-T-OR-D/pittsburg-bridges-T-OR-D_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/pittsburg-bridges-T-OR-D/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'pittsburg-bridges-TYPE':\n",
    "        X_data = pd.read_csv('dataset/pittsburg-bridges-TYPE/pittsburg-bridges-TYPE_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/pittsburg-bridges-TYPE/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'planning':\n",
    "        X_data = pd.read_csv('dataset/planning/planning_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/planning/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'plant-margin':\n",
    "        X_data = pd.read_csv('dataset/plant-margin/plant-margin_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/plant-margin/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'plant-shape':\n",
    "        X_data = pd.read_csv('dataset/plant-shape/plant-shape_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/plant-shape/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'plant-texture':\n",
    "        X_data = pd.read_csv('dataset/plant-texture/plant-texture_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/plant-texture/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'post-operative':\n",
    "        X_data = pd.read_csv('dataset/post-operative/post-operative_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/post-operative/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'primary-tumor':\n",
    "        X_data = pd.read_csv('dataset/primary-tumor/primary-tumor_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/primary-tumor/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'ringnorm':\n",
    "        X_data = pd.read_csv('dataset/ringnorm/ringnorm_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/ringnorm/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'seeds':\n",
    "        X_data = pd.read_csv('dataset/seeds/seeds_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/seeds/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'semeion':\n",
    "        X_data = pd.read_csv('dataset/semeion/semeion_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/semeion/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'soybean':\n",
    "        X_data = pd.read_csv('dataset/soybean/soybean_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/soybean/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'spambase':\n",
    "        X_data = pd.read_csv('dataset/spambase/spambase_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/spambase/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'spect':\n",
    "        X_data = pd.read_csv('dataset/spect/spect_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/spect/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'spectf':\n",
    "        X_data = pd.read_csv('dataset/spectf/spectf_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/spectf/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'statlog-australian-credit':\n",
    "        X_data = pd.read_csv('dataset/statlog-australian-credit/statlog-australian-credit_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/statlog-australian-credit/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'statlog-german-credit':\n",
    "        X_data = pd.read_csv('dataset/statlog-german-credit/statlog-german-credit_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/statlog-german-credit/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'statlog-heart':\n",
    "        X_data = pd.read_csv('dataset/statlog-heart/statlog-heart_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/statlog-heart/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'statlog-image':\n",
    "        X_data = pd.read_csv('dataset/statlog-image/statlog-image_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/statlog-image/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'statlog-landsat':\n",
    "        X_data = pd.read_csv('dataset/statlog-landsat/statlog-landsat_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/statlog-landsat/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'statlog-shuttle':\n",
    "        X_data = pd.read_csv('dataset/statlog-shuttle/statlog-shuttle_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/statlog-shuttle/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'statlog-vehicle':\n",
    "        X_data = pd.read_csv('dataset/statlog-vehicle/statlog-vehicle_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/statlog-vehicle/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'steel-plates':\n",
    "        X_data = pd.read_csv('dataset/steel-plates/steel-plates_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/steel-plates/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'synthetic-control':\n",
    "        X_data = pd.read_csv('dataset/synthetic-control/synthetic-control_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/synthetic-control/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'teaching':\n",
    "        X_data = pd.read_csv('dataset/teaching/teaching_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/teaching/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'thyroid':\n",
    "        X_data = pd.read_csv('dataset/thyroid/thyroid_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/thyroid/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'tic-tac-toe':\n",
    "        X_data = pd.read_csv('dataset/tic-tac-toe/tic-tac-toe_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/tic-tac-toe/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'titanic':\n",
    "        X_data = pd.read_csv('dataset/titanic/titanic_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/titanic/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'trains':\n",
    "        X_data = pd.read_csv('dataset/trains/trains_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/trains/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'twonorm':\n",
    "        X_data = pd.read_csv('dataset/twonorm/twonorm_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/twonorm/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'vertebral-column-2clases':\n",
    "        X_data = pd.read_csv('dataset/vertebral-column-2clases/vertebral-column-2clases_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/vertebral-column-2clases/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'vertebral-column-3clases':\n",
    "        X_data = pd.read_csv('dataset/vertebral-column-3clases/vertebral-column-3clases_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/vertebral-column-3clases/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'wall-following':\n",
    "        X_data = pd.read_csv('dataset/wall-following/wall-following_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/wall-following/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'waveform':\n",
    "        X_data = pd.read_csv('dataset/waveform/waveform_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/waveform/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'waveform-noise':\n",
    "        X_data = pd.read_csv('dataset/waveform-noise/waveform-noise_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/waveform-noise/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'wine':\n",
    "        X_data = pd.read_csv('dataset/wine/wine_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/wine/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'wine-quality-red':\n",
    "        X_data = pd.read_csv('dataset/wine-quality-red/wine-quality-red_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/wine-quality-red/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'wine-quality-white':\n",
    "        X_data = pd.read_csv('dataset/wine-quality-white/wine-quality-white_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/wine-quality-white/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'yeast':\n",
    "        X_data = pd.read_csv('dataset/yeast/yeast_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/yeast/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    elif dataset == 'zoo':\n",
    "        X_data = pd.read_csv('dataset/zoo/zoo_py.dat', header=None, delimiter=',')\n",
    "        X = np.array(X_data)\n",
    "        y = pd.read_csv('dataset/zoo/labels_py.dat', header=None, delimiter=',')\n",
    "        y = np.array(y, dtype=int).ravel()\n",
    "\n",
    "    else:\n",
    "        ValueError('Unknown results set!')\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_estimator(method='wodt', max_depth=5, n_estimators=10):\n",
    "    if method == 'wodt':\n",
    "        return WeightedObliqueDecisionTreeClassifier(max_depth=max_depth)\n",
    "    elif method == 'oc1':\n",
    "        return ObliqueClassifier1(max_depth=max_depth)\n",
    "    elif method == 'stdt':\n",
    "        return DecisionTreeClassifier(max_depth=max_depth)\n",
    "    elif method == 'ndt':\n",
    "        return NDTClassifier(max_depth=max_depth)\n",
    "    elif method == 'wodt_bag':\n",
    "        return BaggingClassifier(base_estimator=WeightedObliqueDecisionTreeClassifier(max_depth=max_depth), n_estimators=n_estimators)\n",
    "    elif method == 'oc1_bag':\n",
    "        return BaggingClassifier(base_estimator=ObliqueClassifier1(max_depth=max_depth), n_estimators=n_estimators)\n",
    "    elif method == 'stdt_bag':\n",
    "        return BaggingClassifier(base_estimator=DecisionTreeClassifier(max_depth=max_depth), n_estimators=n_estimators)\n",
    "    elif method == 'ndt_bag':\n",
    "        return BaggingClassifier(base_estimator=NDTClassifier(max_depth=max_depth), n_estimators=n_estimators)\n",
    "    elif method == 'hhcart':\n",
    "        return HHCartClassifier(MSE(),MeanSegmentor(), max_depth = max_depth)\n",
    "    elif method == 'randcart':\n",
    "        return RandCARTClassifier(MSE(),MeanSegmentor(), max_depth = max_depth)\n",
    "    elif method == 'co2':\n",
    "        return CO2Classifier(MSE(),MeanSegmentor(), max_depth = max_depth)\n",
    "    elif method == 'hhcart_bag':\n",
    "        return BaggingClassifier(base_estimator=HHCartClassifier(MSE(),MeanSegmentor(),max_depth=max_depth), n_estimators=n_estimators)\n",
    "    elif method == 'randcart_bag':\n",
    "        return BaggingClassifier(base_estimator=RandCARTClassifier(MSE(),MeanSegmentor(),max_depth=max_depth), n_estimators=n_estimators)\n",
    "    elif method == 'co2_bag':\n",
    "        return BaggingClassifier(base_estimator=CO2Classifier(MSE(),MeanSegmentor(),max_depth=max_depth), n_estimators=n_estimators)\n",
    "    elif method == 'random_forest':\n",
    "        return RandomForestClassifier(max_depth=max_depth, n_estimators=n_estimators)\n",
    "    else:\n",
    "        ValueError('Unknown model!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def evaluate(datasets_to_evaluate, method_to_evaluate, local_file='.co2.csv'):\n",
    "    n_estimators = 5\n",
    "    max_depths = range(8, 11)  # Test for n_depths = 8 to 10\n",
    "\n",
    "    # Load or initialize the results DataFrame\n",
    "    if os.path.exists(local_file):\n",
    "        results_df = pd.read_csv(local_file, index_col=0)\n",
    "    else:\n",
    "        results_df = pd.DataFrame(index=datasets_to_evaluate, columns=[method_to_evaluate])\n",
    "        results_df.fillna(0.0, inplace=True)\n",
    "\n",
    "    for dataset in datasets_to_evaluate:\n",
    "        # Skip dataset if already evaluated for the given method\n",
    "        if dataset in results_df.index and not pd.isna(results_df.at[dataset, method_to_evaluate]) and results_df.at[dataset, method_to_evaluate] > 0:\n",
    "\n",
    "            print(f\"Skipping dataset '{dataset}', already evaluated.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"\\n--- Evaluating dataset: {dataset}\")\n",
    "\n",
    "        # Preprocess the dataset\n",
    "        X, y = pre_process(dataset)\n",
    "        train_X, test_X, train_Y, test_Y = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "        accuracies = []  # Store accuracies for each depth\n",
    "\n",
    "        for n_depths in max_depths:\n",
    "            print(f\"  Testing {method_to_evaluate} with max_depth={n_depths}\")\n",
    "\n",
    "            if method_to_evaluate == 'dndt':\n",
    "                transformed_Y = np.reshape(train_Y, (-1, 1))\n",
    "                onehotencoder = OneHotEncoder()\n",
    "                transformed_Y = onehotencoder.fit_transform(transformed_Y).toarray()\n",
    "                d = X.shape[1]\n",
    "                num_class = len(np.unique(y))\n",
    "                Y_pred = dndt_fit(train_X, test_X, transformed_Y, d, num_class, 1)\n",
    "\n",
    "            elif method_to_evaluate == 'dndt_bag':\n",
    "                transformed_Y = np.reshape(train_Y, (-1, 1))\n",
    "                onehotencoder = OneHotEncoder()\n",
    "                transformed_Y = onehotencoder.fit_transform(transformed_Y).toarray()\n",
    "                d = X.shape[1]\n",
    "                num_class = len(np.unique(y))\n",
    "                Y_pred = dndt_fit(train_X, test_X, transformed_Y, d, num_class, n_estimators)\n",
    "\n",
    "            else:\n",
    "                # Train model using other estimators\n",
    "                estimator = make_estimator(method=method_to_evaluate, max_depth=n_depths, n_estimators=n_estimators)\n",
    "                estimator.fit(train_X, train_Y)\n",
    "                Y_pred = estimator.predict(test_X)\n",
    "\n",
    "            acc = np.mean(Y_pred == test_Y)\n",
    "            accuracies.append(acc)\n",
    "\n",
    "        # Average accuracy across depths\n",
    "        avg_accuracy = np.mean(accuracies)\n",
    "        results_df.loc[dataset, method_to_evaluate] = avg_accuracy\n",
    "\n",
    "        # Save progress to CSV after evaluating each dataset\n",
    "        results_df.to_csv(local_file)\n",
    "\n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    datasets = ['abalone','acute-inflammation','annealing','arrhythmia','audiology-std','balance-scale','balloons','bank','blood','breast-cancer','breast-cancer-wisc','breast-cancer-wisc-diag','breast-cancer-wisc-prog','breast-tissue','car','cardiotocography-3clases','cardiotocography-10clases','chess-krvkp','congressional-voting','conn-bench-sonar-mines-rocks','conn-bench-vowel-deterding','contrac','credit-approval','cylinder-bands','dermatology','echocardiogram','ecoli','energy-y1','energy-y2','fertility','flags','glass','haberman-survival','hayes-roth','heart-cleveland','heart-hungarian','heart-switzerland','heart-va','hepatitis','hill-valley','horse-colic','ilpd-indian-liver','image-segmentation','ionosphere','iris','led-display','lenses','libras','low-res-spect','lung-cancer','lymphography','mammographic','molec-biol-promoter','molec-biol-splice','monks-1','monks-2','monks-3','musk-1','oocytes_merluccius_nucleus_4d','oocytes_merluccius_states_2f','oocytes_trisopterus_nucleus_2f','oocytes_trisopterus_states_5b','ozone','parkinsons','pima','pittsburg-bridges-MATERIAL','pittsburg-bridges-REL-L','pittsburg-bridges-SPAN','pittsburg-bridges-T-OR-D','pittsburg-bridges-TYPE','planning','plant-margin','plant-shape','plant-texture','post-operative','primary-tumor','seeds','semeion','soybean','spect','spectf','statlog-australian-credit','statlog-german-credit','statlog-heart','statlog-image','statlog-vehicle','steel-plates','synthetic-control','teaching','tic-tac-toe','titanic','trains','vertebral-column-2clases','vertebral-column-3clases','wine','wine-quality-red','yeast','zoo']\n",
    "    methods = ['oc1_bag']\n",
    "    co2_bag =  evaluate(datasets, methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating dataset: adult\n",
      "  Testing co2_bag with max_depth=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\asif hussain\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m datasets \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madult\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      4\u001b[0m method \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mco2_bag\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 5\u001b[0m ndt_bag \u001b[38;5;241m=\u001b[39m  \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatasets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[9], line 55\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(datasets_to_evaluate, method_to_evaluate, local_file)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;66;03m# Train model using other estimators\u001b[39;00m\n\u001b[0;32m     54\u001b[0m     estimator \u001b[38;5;241m=\u001b[39m make_estimator(method\u001b[38;5;241m=\u001b[39mmethod_to_evaluate, max_depth\u001b[38;5;241m=\u001b[39mn_depths, n_estimators\u001b[38;5;241m=\u001b[39mn_estimators)\n\u001b[1;32m---> 55\u001b[0m     \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_Y\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m     Y_pred \u001b[38;5;241m=\u001b[39m estimator\u001b[38;5;241m.\u001b[39mpredict(test_X)\n\u001b[0;32m     58\u001b[0m acc \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(Y_pred \u001b[38;5;241m==\u001b[39m test_Y)\n",
      "File \u001b[1;32mc:\\Users\\asif hussain\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:337\u001b[0m, in \u001b[0;36mBaseBagging.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    328\u001b[0m \u001b[38;5;66;03m# Convert data (X is required to be 2d and indexable)\u001b[39;00m\n\u001b[0;32m    329\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m    330\u001b[0m     X,\n\u001b[0;32m    331\u001b[0m     y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    335\u001b[0m     multi_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    336\u001b[0m )\n\u001b[1;32m--> 337\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\asif hussain\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:472\u001b[0m, in \u001b[0;36mBaseBagging._fit\u001b[1;34m(self, X, y, max_samples, max_depth, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    469\u001b[0m seeds \u001b[38;5;241m=\u001b[39m random_state\u001b[38;5;241m.\u001b[39mrandint(MAX_INT, size\u001b[38;5;241m=\u001b[39mn_more_estimators)\n\u001b[0;32m    470\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_seeds \u001b[38;5;241m=\u001b[39m seeds\n\u001b[1;32m--> 472\u001b[0m all_results \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    473\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parallel_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    475\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_estimators\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_estimators\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseeds\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstarts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstarts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_n_estimators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    486\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    487\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[38;5;66;03m# Reduce\u001b[39;00m\n\u001b[0;32m    490\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_ \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[0;32m    491\u001b[0m     itertools\u001b[38;5;241m.\u001b[39mchain\u001b[38;5;241m.\u001b[39mfrom_iterable(t[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m all_results)\n\u001b[0;32m    492\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\asif hussain\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\asif hussain\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\asif hussain\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\asif hussain\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\asif hussain\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:144\u001b[0m, in \u001b[0;36m_parallel_build_estimators\u001b[1;34m(n_estimators, ensemble, X, y, sample_weight, seeds, total_n_estimators, verbose, check_input)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    143\u001b[0m     X_ \u001b[38;5;241m=\u001b[39m X[indices][:, features] \u001b[38;5;28;01mif\u001b[39;00m requires_feature_indexing \u001b[38;5;28;01melse\u001b[39;00m X[indices]\n\u001b[1;32m--> 144\u001b[0m     \u001b[43mestimator_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    146\u001b[0m estimators\u001b[38;5;241m.\u001b[39mappend(estimator)\n\u001b[0;32m    147\u001b[0m estimators_features\u001b[38;5;241m.\u001b[39mappend(features)\n",
      "File \u001b[1;32md:\\vs code\\DecisionTrees\\Ensembles_of_Oblique_Decision_Trees\\Decision_trees\\CO2.py:206\u001b[0m, in \u001b[0;36mContinuouslyOptimizedObliqueTree.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    203\u001b[0m n_samples, n_features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m    204\u001b[0m X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhstack([X, np\u001b[38;5;241m.\u001b[39mones((n_samples, \u001b[38;5;241m1\u001b[39m))])                         \u001b[38;5;66;03m# Augment the examples with a vector of ones\u001b[39;00m\n\u001b[1;32m--> 206\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_root \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\vs code\\DecisionTrees\\Ensembles_of_Oblique_Decision_Trees\\Decision_trees\\CO2.py:195\u001b[0m, in \u001b[0;36mContinuouslyOptimizedObliqueTree._generate_node\u001b[1;34m(self, X, y, cur_depth)\u001b[0m\n\u001b[0;32m    190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_leaf_node(cur_depth, y)\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    192\u001b[0m     node \u001b[38;5;241m=\u001b[39m CO2Node(cur_depth, y,\n\u001b[0;32m    193\u001b[0m                    weights\u001b[38;5;241m=\u001b[39mweights, bias\u001b[38;5;241m=\u001b[39mbias, pl \u001b[38;5;241m=\u001b[39m pl, pr\u001b[38;5;241m=\u001b[39m pr,\n\u001b[0;32m    194\u001b[0m                    left_child\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_node(X_left, y_left, cur_depth \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m--> 195\u001b[0m                    right_child\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_right\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_right\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcur_depth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    196\u001b[0m                    is_leaf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nodes\u001b[38;5;241m.\u001b[39mappend(node)\n\u001b[0;32m    199\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m node\n",
      "File \u001b[1;32md:\\vs code\\DecisionTrees\\Ensembles_of_Oblique_Decision_Trees\\Decision_trees\\CO2.py:194\u001b[0m, in \u001b[0;36mContinuouslyOptimizedObliqueTree._generate_node\u001b[1;34m(self, X, y, cur_depth)\u001b[0m\n\u001b[0;32m    190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_leaf_node(cur_depth, y)\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    192\u001b[0m     node \u001b[38;5;241m=\u001b[39m CO2Node(cur_depth, y,\n\u001b[0;32m    193\u001b[0m                    weights\u001b[38;5;241m=\u001b[39mweights, bias\u001b[38;5;241m=\u001b[39mbias, pl \u001b[38;5;241m=\u001b[39m pl, pr\u001b[38;5;241m=\u001b[39m pr,\n\u001b[1;32m--> 194\u001b[0m                    left_child\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_left\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_left\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcur_depth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    195\u001b[0m                    right_child\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_node(X_right, y_right, cur_depth \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m    196\u001b[0m                    is_leaf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nodes\u001b[38;5;241m.\u001b[39mappend(node)\n\u001b[0;32m    199\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m node\n",
      "File \u001b[1;32md:\\vs code\\DecisionTrees\\Ensembles_of_Oblique_Decision_Trees\\Decision_trees\\CO2.py:194\u001b[0m, in \u001b[0;36mContinuouslyOptimizedObliqueTree._generate_node\u001b[1;34m(self, X, y, cur_depth)\u001b[0m\n\u001b[0;32m    190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_leaf_node(cur_depth, y)\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    192\u001b[0m     node \u001b[38;5;241m=\u001b[39m CO2Node(cur_depth, y,\n\u001b[0;32m    193\u001b[0m                    weights\u001b[38;5;241m=\u001b[39mweights, bias\u001b[38;5;241m=\u001b[39mbias, pl \u001b[38;5;241m=\u001b[39m pl, pr\u001b[38;5;241m=\u001b[39m pr,\n\u001b[1;32m--> 194\u001b[0m                    left_child\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_left\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_left\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcur_depth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    195\u001b[0m                    right_child\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_node(X_right, y_right, cur_depth \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m    196\u001b[0m                    is_leaf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nodes\u001b[38;5;241m.\u001b[39mappend(node)\n\u001b[0;32m    199\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m node\n",
      "File \u001b[1;32md:\\vs code\\DecisionTrees\\Ensembles_of_Oblique_Decision_Trees\\Decision_trees\\CO2.py:194\u001b[0m, in \u001b[0;36mContinuouslyOptimizedObliqueTree._generate_node\u001b[1;34m(self, X, y, cur_depth)\u001b[0m\n\u001b[0;32m    190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_leaf_node(cur_depth, y)\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    192\u001b[0m     node \u001b[38;5;241m=\u001b[39m CO2Node(cur_depth, y,\n\u001b[0;32m    193\u001b[0m                    weights\u001b[38;5;241m=\u001b[39mweights, bias\u001b[38;5;241m=\u001b[39mbias, pl \u001b[38;5;241m=\u001b[39m pl, pr\u001b[38;5;241m=\u001b[39m pr,\n\u001b[1;32m--> 194\u001b[0m                    left_child\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_left\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_left\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcur_depth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    195\u001b[0m                    right_child\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_node(X_right, y_right, cur_depth \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m    196\u001b[0m                    is_leaf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nodes\u001b[38;5;241m.\u001b[39mappend(node)\n\u001b[0;32m    199\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m node\n",
      "File \u001b[1;32md:\\vs code\\DecisionTrees\\Ensembles_of_Oblique_Decision_Trees\\Decision_trees\\CO2.py:140\u001b[0m, in \u001b[0;36mContinuouslyOptimizedObliqueTree._generate_node\u001b[1;34m(self, X, y, cur_depth)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m converged:\n\u001b[0;32m    139\u001b[0m     w_old \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcopy(w)\n\u001b[1;32m--> 140\u001b[0m     old_objective \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobjective\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw_old\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthetaL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthetaR\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtau \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n\u001b[0;32m    142\u001b[0m         sample \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(n_samples, size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)                           \u001b[38;5;66;03m# considering all the samples\u001b[39;00m\n",
      "File \u001b[1;32md:\\vs code\\DecisionTrees\\Ensembles_of_Oblique_Decision_Trees\\Decision_trees\\CO2.py:113\u001b[0m, in \u001b[0;36mContinuouslyOptimizedObliqueTree.objective\u001b[1;34m(self, X, y, w, thetaL, thetaR)\u001b[0m\n\u001b[0;32m    111\u001b[0m boundR \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(X, w) \u001b[38;5;241m+\u001b[39m loglikR\n\u001b[0;32m    112\u001b[0m loss \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack((boundL, boundR))\n\u001b[1;32m--> 113\u001b[0m objective \u001b[38;5;241m=\u001b[39m (np\u001b[38;5;241m.\u001b[39mmax(loss, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39mabs(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m)\u001b[49m))\u001b[38;5;241m.\u001b[39msum()\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m objective\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    datasets = ['adult']\n",
    "    method = 'co2_bag'\n",
    "    ndt_bag =  evaluate(datasets, method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating dataset: cylinder-bands\n",
      "  Testing ndt_bag with max_depth=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\asif hussain\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "d:\\vs code\\DecisionTrees\\Ensembles_of_Oblique_Decision_Trees\\Decision_trees\\Oblique_Classifier_1.py:155: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  majority, count = mode(y)  # NOTE that if there is more than one mode, scipy.mode() returns the smallest one\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Testing ndt_bag with max_depth=9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\asif hussain\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "d:\\vs code\\DecisionTrees\\Ensembles_of_Oblique_Decision_Trees\\Decision_trees\\Oblique_Classifier_1.py:155: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  majority, count = mode(y)  # NOTE that if there is more than one mode, scipy.mode() returns the smallest one\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Testing ndt_bag with max_depth=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\asif hussain\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "d:\\vs code\\DecisionTrees\\Ensembles_of_Oblique_Decision_Trees\\Decision_trees\\Oblique_Classifier_1.py:155: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  majority, count = mode(y)  # NOTE that if there is more than one mode, scipy.mode() returns the smallest one\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating dataset: dermatology\n",
      "  Testing ndt_bag with max_depth=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\asif hussain\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "d:\\vs code\\DecisionTrees\\Ensembles_of_Oblique_Decision_Trees\\Decision_trees\\Oblique_Classifier_1.py:155: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  majority, count = mode(y)  # NOTE that if there is more than one mode, scipy.mode() returns the smallest one\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Testing ndt_bag with max_depth=9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\asif hussain\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "d:\\vs code\\DecisionTrees\\Ensembles_of_Oblique_Decision_Trees\\Decision_trees\\Oblique_Classifier_1.py:155: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  majority, count = mode(y)  # NOTE that if there is more than one mode, scipy.mode() returns the smallest one\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Testing ndt_bag with max_depth=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\asif hussain\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "d:\\vs code\\DecisionTrees\\Ensembles_of_Oblique_Decision_Trees\\Decision_trees\\Oblique_Classifier_1.py:155: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  majority, count = mode(y)  # NOTE that if there is more than one mode, scipy.mode() returns the smallest one\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating dataset: image-segmentation\n",
      "  Testing ndt_bag with max_depth=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\asif hussain\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "d:\\vs code\\DecisionTrees\\Ensembles_of_Oblique_Decision_Trees\\Decision_trees\\Oblique_Classifier_1.py:155: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  majority, count = mode(y)  # NOTE that if there is more than one mode, scipy.mode() returns the smallest one\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Testing ndt_bag with max_depth=9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\asif hussain\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "d:\\vs code\\DecisionTrees\\Ensembles_of_Oblique_Decision_Trees\\Decision_trees\\Oblique_Classifier_1.py:155: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  majority, count = mode(y)  # NOTE that if there is more than one mode, scipy.mode() returns the smallest one\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Testing ndt_bag with max_depth=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\asif hussain\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "d:\\vs code\\DecisionTrees\\Ensembles_of_Oblique_Decision_Trees\\Decision_trees\\Oblique_Classifier_1.py:155: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  majority, count = mode(y)  # NOTE that if there is more than one mode, scipy.mode() returns the smallest one\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating dataset: oocytes_merluccius_states_2f\n",
      "  Testing ndt_bag with max_depth=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\asif hussain\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "d:\\vs code\\DecisionTrees\\Ensembles_of_Oblique_Decision_Trees\\Decision_trees\\Oblique_Classifier_1.py:155: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  majority, count = mode(y)  # NOTE that if there is more than one mode, scipy.mode() returns the smallest one\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Testing ndt_bag with max_depth=9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\asif hussain\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "d:\\vs code\\DecisionTrees\\Ensembles_of_Oblique_Decision_Trees\\Decision_trees\\Oblique_Classifier_1.py:155: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  majority, count = mode(y)  # NOTE that if there is more than one mode, scipy.mode() returns the smallest one\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Testing ndt_bag with max_depth=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\asif hussain\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "d:\\vs code\\DecisionTrees\\Ensembles_of_Oblique_Decision_Trees\\Decision_trees\\Oblique_Classifier_1.py:155: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  majority, count = mode(y)  # NOTE that if there is more than one mode, scipy.mode() returns the smallest one\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating dataset: oocytes_trisopterus_nucleus_2f\n",
      "  Testing ndt_bag with max_depth=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\asif hussain\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "d:\\vs code\\DecisionTrees\\Ensembles_of_Oblique_Decision_Trees\\Decision_trees\\Oblique_Classifier_1.py:155: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  majority, count = mode(y)  # NOTE that if there is more than one mode, scipy.mode() returns the smallest one\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Testing ndt_bag with max_depth=9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\asif hussain\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "d:\\vs code\\DecisionTrees\\Ensembles_of_Oblique_Decision_Trees\\Decision_trees\\Oblique_Classifier_1.py:155: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  majority, count = mode(y)  # NOTE that if there is more than one mode, scipy.mode() returns the smallest one\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Testing ndt_bag with max_depth=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\asif hussain\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "d:\\vs code\\DecisionTrees\\Ensembles_of_Oblique_Decision_Trees\\Decision_trees\\Oblique_Classifier_1.py:155: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  majority, count = mode(y)  # NOTE that if there is more than one mode, scipy.mode() returns the smallest one\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating dataset: oocytes_trisopterus_states_5b\n",
      "  Testing ndt_bag with max_depth=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\asif hussain\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "d:\\vs code\\DecisionTrees\\Ensembles_of_Oblique_Decision_Trees\\Decision_trees\\Oblique_Classifier_1.py:155: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  majority, count = mode(y)  # NOTE that if there is more than one mode, scipy.mode() returns the smallest one\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Testing ndt_bag with max_depth=9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\asif hussain\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "d:\\vs code\\DecisionTrees\\Ensembles_of_Oblique_Decision_Trees\\Decision_trees\\Oblique_Classifier_1.py:155: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  majority, count = mode(y)  # NOTE that if there is more than one mode, scipy.mode() returns the smallest one\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Testing ndt_bag with max_depth=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\asif hussain\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "d:\\vs code\\DecisionTrees\\Ensembles_of_Oblique_Decision_Trees\\Decision_trees\\Oblique_Classifier_1.py:155: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  majority, count = mode(y)  # NOTE that if there is more than one mode, scipy.mode() returns the smallest one\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating dataset: parkinsons\n",
      "  Testing ndt_bag with max_depth=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\asif hussain\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "d:\\vs code\\DecisionTrees\\Ensembles_of_Oblique_Decision_Trees\\Decision_trees\\Oblique_Classifier_1.py:155: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  majority, count = mode(y)  # NOTE that if there is more than one mode, scipy.mode() returns the smallest one\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Testing ndt_bag with max_depth=9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\asif hussain\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "d:\\vs code\\DecisionTrees\\Ensembles_of_Oblique_Decision_Trees\\Decision_trees\\Oblique_Classifier_1.py:155: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  majority, count = mode(y)  # NOTE that if there is more than one mode, scipy.mode() returns the smallest one\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Testing ndt_bag with max_depth=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\asif hussain\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "d:\\vs code\\DecisionTrees\\Ensembles_of_Oblique_Decision_Trees\\Decision_trees\\Oblique_Classifier_1.py:155: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  majority, count = mode(y)  # NOTE that if there is more than one mode, scipy.mode() returns the smallest one\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    datasets = ['cylinder-bands','dermatology','image-segmentation','oocytes_merluccius_states_2f','oocytes_trisopterus_nucleus_2f','oocytes_trisopterus_states_5b','parkinsons']\n",
    "    methods = 'ndt_bag'\n",
    "    ndt_bag =  evaluate(datasets, methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    datasets = ['abalone','acute-inflammation','adult','annealing','arrhythmia','audiology-std','balance-scale','balloons','bank','blood','breast-cancer','breast-cancer-wisc','breast-cancer-wisc-diag','breast-cancer-wisc-prog','breast-tissue','car','cardiotocography-3clases','cardiotocography-10clases','chess-krvk','chess-krvkp','congressional-voting','conn-bench-sonar-mines-rocks','conn-bench-vowel-deterding','connect-4','contrac','credit-approval','cylinder-bands','dermatology','echocardiogram','ecoli','energy-y1','energy-y2','fertility','flags','glass','haberman-survival','hayes-roth','heart-cleveland','heart-hungarian','heart-switzerland','heart-va','hepatitis','hill-valley','horse-colic','ilpd-indian-liver','image-segmentation','ionosphere','iris','led-display','lenses','letter','libras','low-res-spect','lung-cancer','lymphography','magic','mammographic','miniboone','molec-biol-promoter','molec-biol-splice','monks-1','monks-2','monks-3','mushroom','musk-1','musk-2','nursery','oocytes_merluccius_nucleus_4d','oocytes_merluccius_states_2f','oocytes_trisopterus_nucleus_2f','oocytes_trisopterus_states_5b','optical','ozone','page-blocks','parkinsons','pendigits','pima','pittsburg-bridges-MATERIAL','pittsburg-bridges-REL-L','pittsburg-bridges-SPAN','pittsburg-bridges-T-OR-D','pittsburg-bridges-TYPE','planning','plant-margin','plant-shape','plant-texture','post-operative','primary-tumor','ringnorm','seeds','semeion','soybean','spambase','spect','spectf','statlog-australian-credit','statlog-german-credit','statlog-heart','statlog-image','statlog-landsat','statlog-shuttle','statlog-vehicle','steel-plates','synthetic-control','teaching','thyroid','tic-tac-toe','titanic','trains','twonorm','vertebral-column-2clases','vertebral-column-3clases','wall-following','waveform','waveform-noise','wine','wine-quality-red','wine-quality-white','yeast','zoo']\n",
    "    methods = ['oc1_bag']\n",
    "    results2 =  evaluate(datasets, methods)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
